---
title: "Lab 5"
author: "My Name"
output:
  pdf_document:
    fig_caption: yes
    number_sections: true
header-includes:
  - |
    ```{=latex}
    \usepackage{fvextra}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{
      breaksymbolleft={}, 
      showspaces = false,
      showtabs = false,
      breaklines,
      commandchars=\\\{\}
    }
    ```
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  tidy.opts=list(width.cutoff=70),
  tidy=TRUE
)
```

# Lab 5 (Set 2): Collocations {-}

This is a short lab that introduces the concept of:

* collocations,
* how to calculate word association measures like pointwise mutual information, and
* how to plot collocational networks.

This lab will also cover the process of reading in a corpus from a directory of text files.

# Load the needed packages 

```{r setup, message = FALSE, error=FALSE, warning=FALSE}
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(ggraph)
```

Load data:

```{r}
load("../data/sample_corpus.rda")
```

Load functions:

```{r}
source("../R/helper_functions.R")
source("../R/utility_functions.R")
source("../R/collocation_functions.R")
```

# Prepare the data

First, we'll pre-process our text, create a corpus and tokenize the data:

```{r tokens}
sc_tokens <- sample_corpus %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)
```

# Collocates by mutual information (MI)

The **collocates_by_MI( )** function produces collocation measures (by pointwise mutual information) for a specified token in a **quanteda tokens** object. In addition to a token, a span or window (as given by a number of words to the **left** and **right** of the **node word**) is required. The default is 5 to the left and 5 to the right.

The formula for calculating MI is as follows:

$$log_{2} \frac{O_{11}}{E_{11}}$$
Where *O~11~* and *E~11~* are the observed (i.e., node + collocate) and expected frequencies of the node word within a given window. The expected frequency is given by:

$$E_{11} = \frac{R_{1} \times C_{1}}{N}$$

* *N* is the number of words in the corpus
* *R~1~* is the frequency of the node in the whole corpus
* *C~1~*  is the frequency of the collocate in the whole corpus

We'll start by making a table of tokens that collocate with the token *money*.

```{r coll_money}
money_collocations <- collocates_by_MI(sc_tokens, "money")
```

Check the result:

```{r echo=FALSE}
knitr::kable(head(money_collocations), digits = 3)
```

Now, let's make a similar table for collocates of *time*.

```{r coll_time}
time_collocations <- collocates_by_MI(sc_tokens, "time")
```


```{r echo=FALSE}
knitr::kable(head(time_collocations), digits = 3)
```

As is clear from the above table, MI is sensitive to rare/infrequent words. Because of that sensitivity, it commmon to make thresholds for both token frequency (absolute frequency) and MI score (usually at some value $\ge$ 3).

For our purposes, we'll filter for AF $\ge$ 5 and MI $\ge$ 5.

```{r filter}
tc <- time_collocations %>% filter(col_freq >= 5 & MI_1 >= 5)
mc <- money_collocations %>% filter(col_freq >= 5 & MI_1 >= 5)
```

Check the result:

```{r echo=FALSE}
knitr::kable(head(tc), digits = 3)
```

```{r echo=FALSE}
knitr::kable(head(mc), digits = 3)
```

___
\begin{center}
STOP!\\
COMPLETE TASK 1
\end{center} 
___

# Create a tbl_graph object for plotting

A [**tbl_graph**](https://www.data-imaginist.com/2017/introducing-tidygraph/) is a data structure for **tidyvers** (ggplot2) network plotting.

For this, we'll use the **col_network( )** function.

```{r net}
net <- col_network(tc, mc)
```


# Plot network

The network plot shows the tokens that distinctly collocate with either *time* or *money*, as well as those that intersect. The distance from the central tokens (*time* and *money*) is governed by the MI score and the transparency (or alpha) is governed by the token frequency.

The aesthetic details of the plot can be manipulated in the various **ggraph** options.

```{r net_plot, message = FALSE, fig.width = 7, fig.height=4}
ggraph(net, weight = link_weight, layout = "stress") + 
  geom_edge_link(color = "gray80", alpha = .75) + 
  geom_node_point(aes(alpha = node_weight, size = 3, color = n_intersects)) +
  geom_node_text(aes(label = label), repel = T, size = 3) +
  scale_alpha(range = c(0.2, 0.9)) +
  theme_graph() +
  theme(legend.position="none")
```

___
\begin{center}
STOP!\\
COMPLETE TASK 2
\end{center} 
___

# Reading in local files

## Create a vector of file paths

First, go to Canvas and dowload the **screenplay_corpus** (in the Data folder under Files). Unzip the corpus and note/copy the path to the folder.

Next, we'll create a vector of the file paths. Remember to replace **your path** with the place-holder path in the **list.files()** function.

```{r list_files}
files_list <- list.files("/Users/user/Downloads/screenplay_corpus", full.names = T, pattern = "*.txt")
```

## Read in all files using readtext

Next, we'll read in the files using **readtext**. And for the purposes of efficiency, we'll sample out 50 rows.

```{r readfiles}
set.seed(1234)

sp <- sample(files_list, 50) %>%
  readtext::readtext()
```

## Extract the dialogue

These particular files are formatted using some simple markup. So we'll use the **from_play()** function to extract the dialogue.

```{r dialgue}
sp <- from_play(sp, extract = "dialogue")
```

## Tokenize

```{r tokenize}
sp <-   sp %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)
```

## Calculate MI

Now we'll calculate collocations for the tokens *boy* and *girl*, and filter. Note that we're only looking for tokens 3 words to the left of the node word.

```{r}
b <- collocates_by_MI(sp, "boy", left = 3, right = 0)
b <- b %>% filter(col_freq >= 3 & MI_1 >= 3)

g  <- collocates_by_MI(sp, "girl", left = 3, right = 0)
g <- g %>% filter(col_freq >= 3 & MI_1 >= 3)
```

## Plot the network

```{r, message = FALSE, fig.width = 7, fig.height=4}
net <- col_network(b, g)

ggraph(net, weight = link_weight, layout = "stress") + 
  geom_edge_link(color = "gray80", alpha = .75) + 
  geom_node_point(aes(alpha = node_weight, size = 3, color = n_intersects)) +
  geom_node_text(aes(label = label), repel = T, size = 3) +
  scale_alpha(range = c(0.2, 0.9)) +
  theme_graph() +
  theme(legend.position="none")
```

\break
___
\begin{center}
STOP!\\
COMPLETE TASK 3
\end{center} 
___

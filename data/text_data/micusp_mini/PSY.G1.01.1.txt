Complexity theory, also known as dynamic systems theory, emerged by drawing together ideas from such fields as computer science, mathematics, physics, and ecology. It has sustained its interdisciplinary roots with current applications ranging from ecology to psychology to genetics. Though heavily compacted, the following provides initial ground for a definition: "Complexity theorist search for broad rules applying across levels, from genes to neurons to large groups of people influencing another within international economics" (Kenrick, 2001, p. 14). In essence, complexity theory attempts to understand the ways in which complex dynamical systems (such as neural networks and human cooperation) operate by looking for patterns, which optimally can be formalized into broad rules that govern the behavior of individuals (sometimes referred to as agents) in the system.
Three concepts associated with complexity theory -- drawn from observations of a wide variety of complex dynamic systems -- will bear particular relevance to this paper. The first concept is that great complexity can emerge (leading to frequent use of the term emergence to describe this phenomena) seemingly spontaneously from interactions governed by a few simple parameters. Second, groups of interacting agents (whether they be humans, neurons, or any other organism) often display collective behavior that cannot be accounted for simply by the "program" that governs the behavior of the individual agent. In other words, at times the whole behaves in ways that are not simply the sum of the contributing agents (non-linear dynamics). Finally, self-organization frequently arises as a result of initially random interactions between dynamically linked agents (Nowak & Vallacher, 1998).
Once I began to research complexity theory in greater depth, I found that the concepts transferred nicely on to many of our readings throughout the semester, and also on to many topics in other areas of psychology. The discussion that follows is a brief introduction to the observations, implications, and predictions of complexity theory in relation to the three perspectives that we have examined throughout Psy731: evolution, development, and proximate mechanisms of behavior.
For a psychologist interested in studying complex systems, there can scarcely be a better subject than the brain itself. It is an organ composed of interconnected cells with two states (firing and not firing) interspersed with a number of chemical communicators (hormones, neurotransmitters, etc.). In practice, the situation is a bit more complicated that this, for as Waldrop (1992) notes, "through a microscope, most of the brain appears to be a study in chaos, with each nerve cell sending out thousands of random filaments that connect it willy-nilly to thousands of other nerves cells" (p. 157). But, as Waldrop goes on to discuss, the organization and actions of the brain are decidedly not random, and it not only manages to function but also to incorporate new information and alter its future states accordingly (learning).
John H. Holland was one of the pioneers of generating computer models of proximate neural behavior. In the early and mid-1950's, while working with a group of programmers at IBM, Holland helped develop the first neural network simulator based on the learning theories of Donald O. Hebb. In conjunction with Nathaniel Rochester, Holland created artificial neurons and artificial synapses using early computing technology. The synapses possessed different "weights," meaning that their strength could change in response to changes in the environment in a process akin to learning. As with many models of complex systems, the devil was in the details, namely identifying the correct rules under which the system should operate. Ultimately, however, the simulation was successful. As Holland recounted, "There was a lot of emergence. You could start with a uniform substrate of neurons and see the cell assemblies form" (Waldrop, 1992, p. 159). The research culminated in Holland's first publication, a 1956 paper in IEEE Transactions on Information Theory (Rochester, Holland, et al., 1956).
This early neural simulation did include a number of details about basic neurophysiology, such as maximum firing rate of the simulated neurons and how a cell "tired" under conditions of repeated stimulation. However, as our readings in the third module emphasized there are a number of other proximate parameters in the brain, such as hormones, genes, and the presence/absence of particular receptors, among others. The vast majority of the research that we covered explored how varying manipulations of these generally inherent parameters at different stages of development could impact human behavior, such as by altering neuron survival (Morris et al., 2004) or knocking out genes for particular hormone receptors (Rissman et al., 1999; Scordalakes et al., 2002; Bakker et al., 2003).
Gene knockouts are particularly interesting to consider in light of complex dynamical systems. One characteristic of a number of dynamical systems is a sensitivity to alterations in initial system parameters, meaning that small perturbations in the initial state of affairs can lead to enormous differences over the course of time (both on individual life scales and also evolutionary time scales). A familiar example comes from the realm of meteorology, where small local disturbances caused by the flapping of butterfly wings a continent away could theoretically contribute to a ferocious winter storm here in Ann Arbor. The removal of a gene from the genome certainly is akin to an apparently small, local disturbance with the possibility of altering not only the production of particular proteins or structures that the gene encodes (such as estrogen receptors, which we discussed in class) but also changing the trajectory of the system as a whole. This argument arose in class during a discussion of the drawbacks of knockout studies, and complexity theory provides a framework for further emphasizing the need to consider the long-term ramifications of system disturbances1.
Consider another addition to the complex system of the brain that we considered in our readings: psychoactive drugs. In pure form, these substances have the ability to profoundly alter the functions of proximate neural mechanisms as well as the behavior that the affected neural systems regulate. In terms of complex systems, I found it interesting to think of addiction as an attractor state, or equilibrium point, for certain systems when psychoactive drugs are introduced. What is particularly intriguing is that modifying the system parameters by including psychoactive drugs does not lead to only one outcome, since addiction only occurs in roughly 15-16% of cases (Robinson & Berridge, 2003). This implies that adding psychoactive drugs does not lead to a unimodal system, but rather a multi-stable system with more than one attractor (one being addiction, the other being non-addiction). In such multi-stable systems, random initial variations are often critical in determining which attractor a particular system (or individual) will be drawn to (Kenrick et al., 2003). Understanding these variations may provide great insight into susceptibility to addiction, and research efforts such as those of Robinson & Berridge help narrow the focus to the most important system parameters ("wanting" the drug, as opposed to the hedonic value of the drug).
It was actually one of our readings in the developmental module of the course that sparked my interest in complex systems and my desire to write this paper on the topic. During our readings on the subject of neuroembryology, I recall being struck by how terribly complicated and intricate the process of neural genesis and organization is, and how difficult it would be to create an accurate set of instructions that would lead to the construction of a functional human brain.
During the third week of the second module, we read a chapter by Michel & Moore (1995) regarding neuroembryology. There was only a brief formal mention of emergent properties, noting Waddington's position that "the assembly of organisms is subject to physical laws. However, the organization of the assemblage cannot be derived from the laws -- it is an emergent property" (p. 249). However, in spite of its brief mention the concept seemed to resonate as an underlying principle for many of the processes described in the chapter. Waddington's comment embodies the first of the previously mentioned concepts associated with complexity theory, which is the emergence of great complexity from interactions governed by a few simple principles.
A specific example from the same chapter helps to emphasize emergent complexity as well as another relevant concept, emergent self-organization. Michel and Moore (1995) discuss the phenomenon of neural migration, particularly of neurons along radial glia. The glial cells project long processes that act as migratory roadways for neurons dividing in deeper cortical layers. It is profoundly simpler to construct rules for neural organization utilizing these pathways (find pathway → follow pathway until some specific input is met [such as a particular chemical gradient] → stop migration) than to encode a particular location in a cell for it to travel to. What's more, the former series of instructions is universal and would work for any traveling neuron, whereas the latter specific description would have to be different for each neuron (a fairly onerous task when repeated billions of times over). The same simple rules can be used to describe the migration of cells to other regions, such as the olfactory bulb cells discussed in Najbauer et al. (2002).
Finally, the notion of emergent complexity can shed light on the answer to a question posed by Micky during one of our developmental discussions, a question which I found particularly intriguing. The class was discussing how even at very early stages in development, a pair of MZ twins will experience slightly different intra-uterine environments, and that this may be the beginning of the different trajectories that the two individuals take in life. Micky then raised the issue of whether the supposed randomness in the outcome of MZ twins was truly a random process, or whether our predictive abilities were limited by an inability to obtain precise measurements of the environmental variables. I found this to be an extremely provocative question, and I feel that complexity theory affords at least a partial response. As noted before, groups of agents interacting in a complex environmental system often display behavior that cannot be inferred simply by knowing the rules that govern the system itself. So even though absolute knowledge of hormone gradients and nutrient concentrations in the intra-uterine environment may allow for more precise predictions, complete knowledge regarding the rules and parameters of a complex dynamical system can still lead to unpredictable, non-linear outcomes.
As noted in the background section, complexity theory is in part an attempt to discern broad rules that apply across multiple levels of analysis. As Kenrick (2001) noted, the principle of natural selection can actually be considered such a broad rule, and this parsimonious principle can be used to explain extraordinarily complex and sophisticated behavior. To reference yet another class discussion, at one point during the course Chenfei mentioned the egg-laying behavior of a particular insect species. After fertilization, the female of this species would seek out another insect or small creature, inject a toxin into the creature's spine that would immobilize it, and then lay her eggs on the paralyzed victim, ultimately a source of nourishment for the growing eggs and larvae. Chenfei noted that this behavior seemed so goal-directed and complicated that it was difficult to believe it could originate via evolutionary means. However, as the class ultimately responded, even the simple principle of natural selection could, over a long enough period of time, generate such sophisticated behaviors. The key is to imagine members of the same species that for some reason (perhaps a mutation) adopt a different strategy and compete over many generations. A female who laid her eggs on a live creature would provide better resources for her young than a female who laid her eggs on a tree stump, and this boost in inclusive fitness would lead to a predomination of the former strategy. Add a successive series of mutations and shifts in inclusive fitness (females with poison do better than those who don't, females who inject the poison into a particular spot do better than those who inject non-discriminately, and so on), and eventually a rather complicated behavior emerges from a rather simple rubric.
Consider another example that shows how agents interacting under very simple rules can generate emergent patterns of behavior, taken from Kenrick (2001) and of particular relevance to consideration of Koolhaus et al. (2004). Consider a 6 X 6 grid with all spaces occupied by individuals (agents) who can adopt one of two strategies: aggression or non-aggressive. Agents are initially randomly distributed in the environment, and changes in strategy are governed by the following rule: average the strategies of your neighbors and then adopt the strategy that is most prevalent around you. After only a short series of runs, these randomly distributed agents settle into stable patterns of aggression and non-aggression, as displayed in the figure at right (aggressive individuals are represented by black dots, non-aggressive individuals by white dots). Studies evaluating emergent patterns among neighbors interacting under simple rules have been widely used, such as Schelling's (1971) examination of racially segregated housing patterns and Kenrick et al.'s (2003) research into distributions of mating behavior. Interesting further manipulations of these studies could examine how the behavioral patterns change over time as a result of random influx of new agents or the birth of new generations of agents (which may or may not display the same phenotype as the parents).
These sorts of complex dynamic systems can be used to examine not only patterns of agent distribution, but also how agent behavior emerges in the first place (which is possibly of more concern to psychologists). One of the most widely known examples is Axelrod & Hamilton (1981), in which a computer tournament of agents with varying strategies competing in a Prisoner's Dilemma game was able to demonstrate how cooperation based on reciprocity could emerge, thrive, and resist invasion. In addition to research that relies on computer simulations, complexity theory and related concepts can also be used to evaluate the behavioral development of living organisms. For example, Smuts (2005) is able to use concepts related to complexity theory to explain the divergence in chimpanzee and bonobo social systems.
Although complexity theory and evolutionary theory are not mutually exclusive, they are often utilized in different manners within the field of psychology, particularly when discussing cognitive strategies (Kenrick et al., 2003). Complexity theory is generally paired with content-independent descriptions of human cognitive capacities, which emphasize the general processing ability of the brain. In contrast, many evolutionary psychologists posit that natural selection has shaped specific cognitive capacities that increase fitness in certain recurrent historical situations (such as finding food, allocating resources, etc.). Although easily confused as mutually exclusive (as at times occurs with proximate vs. ultimate explanations), complexity theory and evolution are not oppositional notions. Lasting impressions on psychological inquiry are likely to result from combinations of these two approaches.
Complexity theory offers a powerful lens through which to examine phenomena at a number of levels of psychological inquiry, including the mechanistic, developmental, and evolutionary perspectives that were the core focus of our seminar. A task for the future complexity-minded psychologists will be to examine the broad patterns that are observed, and to explain how complex phenomena at any one level of analysis (proximate, developmental, selective advantage, or phylogenetic) interact with and/or combine with complex outcomes at other levels (Holland, 1998). Kendrick (2001) suggested that a combination of ideas from evolutionary theory, cognitive science, and complex dynamic systems theory could be used to provide an overarching paradigm for psychology. Regardless of whether complexity theory is able to contribute to such a grandiose development as a paradigm shift, its concepts are readily applicable to a number of psychological phenomena and often provide novel insights into complex behavioral and neuropsychological events.

<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE TEI.2 SYSTEM "tei_bawe.dtd">
<TEI.2 id="_0088c" n="version 1.0">
<teiHeader>
<fileDesc>
<titleStmt>
<title>Comparing Binary Search algorithms with a guessing task</title>
</titleStmt>
<extent/>
<publicationStmt>
<distributor>British Academic Written English (BAWE) corpus</distributor>
<availability>
<p>The British Academic Written English (BAWE) corpus was developed at the Universities of Warwick, Reading and Oxford Brookes, under the directorship of Hilary Nesi and Sheena Gardner (formerly of the Centre for Applied Linguistics [previously called CELTE], Warwick), Paul Thompson (Department of Applied Linguistics, Reading) and Paul Wickens (Westminster Institute of Education, Oxford Brookes), with funding from the ESRC. Subject to the rights of the these institutions in the BAWE corpus, and pursuant to the ESRC agreement, the BAWE corpus is available to researchers for research purposes PROVIDED THAT the following conditions are met:</p>
<p>1. The corpus files are not distributed in either their original form or in modified form.</p>
<p>2. The texts are used for research purposes only; they should not be reproduced in teaching materials.</p>
<p>3. The texts are not reproduced in full for a wider audience/readership, although researchers are free to quote short passages of text (up to 200 running words from any given text).</p>
<p>4. The BAWE corpus developers (contact: BAWE@warwick.ac.uk) are informed of all projects, dissertations, theses, presentations or publications arising from analysis of the corpus.</p>
<p>5. Researchers acknowledge their use of the corpus using the following form of words: "The data in this study come from the British Academic Written English (BAWE) corpus, which was developed at the Universities of Warwick, Reading and Oxford Brookes under the directorship of Hilary Nesi and Sheena Gardner (formerly of the Centre for Applied Linguistics [previously called CELTE], Warwick), Paul Thompson (Department of Applied Linguistics, Reading) and Paul Wickens (Westminster Institute of Education, Oxford Brookes), with funding from the ESRC (RES-000-23-0800)."</p>
</availability>
</publicationStmt>
<notesStmt>
<note resp="British Academic Written English (BAWE) corpus project">appendix: source codes and output table</note>
</notesStmt>
<sourceDesc>
<p n="level">4</p>
<p n="date">2004-11</p>
<p n="module title">Practical Research Skills</p>
<p n="module code">PS904</p>
<p n="genre family">Methodology recount</p>
<p n="discipline">Psychology</p>
<p n="disciplinary group">LS</p>
<p n="grade">D</p>
<p n="number of authors">1</p>
<p n="number of words">1215</p>
<p n="number of s-units">54</p>
<p n="number of p">13</p>
<p n="number of tables">1</p>
<p n="number of figures">1</p>
<p n="number of block quotes">0</p>
<p n="number of formulae">0</p>
<p n="number of lists">0</p>
<p n="number of paragraphs formatted like lists">0</p>
<p n="abstract present">abstract present</p>
<p n="average words per s-unit">22.5</p>
<p n="average s-units per p">4.2</p>
<p n="macrotype of assignment">simple assignment</p>
</sourceDesc>
</fileDesc>
<encodingDesc>
<p>TEI P4 (documented in: BAWE.documentation.pdf)</p>
</encodingDesc>
<profileDesc>
<particDesc>
<person>
<p n="gender">m</p>
<p n="year of birth">1976</p>
<p n="first language">Portuguese</p>
<p n="education">OSA</p>
<p n="course">Psychology Msc: Research Methods</p>
<p n="student ID">0088</p>
</person>
</particDesc>
</profileDesc>
</teiHeader>
<text>
<front>
<titlePage>
<titlePart rend="underlined bold">Assessment 1: Delphi Console Program</titlePart>
<titlePart>
<hi rend="bold">Date:</hi> 15 November 2004 <hi rend="bold"> Student: </hi>
<name type="student name"/>
<hi rend="bold"> Number: </hi>
<name type="student ID"/>
<hi rend="bold"> Course:</hi> PS904 <hi rend="bold"> Convenor: </hi>
<name type="tutor name"/>
</titlePart>
<docTitle>
<titlePart rend="underlined bold">Comparing Binary Search algorithms with a guessing task</titlePart>
</docTitle>
</titlePage>
</front>
<body>
<div1 type="abstract">
<p n="p1.13">
<s n="s1.3;p1.13">
<hi rend="bold">Abstract:</hi> <hi rend="italic">We empirically compare the efficiency of two Binary Search algorithms in a number-guessing task with feedback.</hi> </s>
<s rend="italic" n="s2.3;p1.13">The difference between the algorithms is the method used to guess a target item: one chooses an item in the midpoint of a range, whereas the other picks a random item within the range. </s>
<s rend="italic" n="s3.3;p1.13">We show that the former converges faster to the correct answer than the latter, as predicted by complexity theory. </s>
</p>
</div1>
<div1 type="section">
<head rend="bold">Introduction</head>
<p n="p2.13">
<s n="s1.7;p2.13">Searching for a given item in a finite list is a common task in every day life. </s>
<s n="s2.7;p2.13">One searches for telephone numbers in a phonebook or words in a dictionary. </s>
<s n="s3.7;p2.13">In order to automate this process, one might create a computer program that runs sequentially through every word in the dictionary and asks the user whether the word in turn is the one she is looking for. </s>
<s n="s4.7;p2.13">Although this procedure would eventually find the target word, it would take a long time to do so. </s>
<s n="s5.7;p2.13">The time required to complete the task will depend on the relative position of the word in the dictionary: words in the beginning will be found faster than words toward the end. </s>
<s n="s6.7;p2.13">In fact, if the dictionary contains <hi rend="italic">N</hi> words and if every look-up counts as one computation, then it would take at most <hi rend="italic">N</hi> computations to complete the task. </s>
<s n="s7.7;p2.13">And the user would have to reply <hi rend="italic">N</hi> times. </s>
</p>
<p n="p3.13">
<s n="s1.4;p3.13">Fortunately, there is a way to improve the efficiency of the look-up procedure: pick a word in the dictionary and ask whether the target word is further up or down in the sequence; if it is up, delete the lower part; if it is down, delete the upper part; do the same until the target word is reached. </s>
<s n="s2.4;p3.13">This procedure is called <hi rend="italic">Binary Search</hi> because each time a word is picked the procedure splits the search space into two parts and discards one of them. </s>
<s n="s3.4;p3.13">As intuitive as it seems, however, the Binary Search algorithm depends crucially on the criterion used to split the search space. </s>
<s n="s4.4;p3.13">Depending on the criterion chosen one might end up either with the optimal solution or the worst. </s>
</p>
<p n="p4.13">
<s n="s1.4;p4.13">In this paper, we present a comparison between two algorithms that use Binary Search as their core procedure but differ slightly in the criterion used to split the search space: the first (<hi rend="italic">binary search algorithm</hi>) always pick an item in the middle of the search space; the second (<hi rend="italic">random search algorithm</hi>), by contrast, randomly chooses an item in the space. </s>
<s n="s2.4;p4.13">This difference is sufficient to change the worst-case complexity of the first algorithm from <hi rend="italic">O</hi>(log <hi rend="italic">N</hi>), the optimal solution, to <hi rend="italic">O</hi>(N), the worst solution. </s>
<s n="s3.4;p4.13">In order to empirically test that, we compare the performance of both algorithms in a number-guessing task. </s>
<s n="s4.4;p4.13">We hypothesise that <hi rend="italic">binary search</hi> will converge to the correct answer faster and more reliably than <hi rend="italic">random search</hi>. </s>
</p>
</div1>
<div1 type="section">
<head rend="bold">Methods</head>
<div2>
<head rend="bold">Task</head>
<p n="p5.13">
<s n="s1.6;p5.13">The task consisted of guessing a number chosen by the user. </s>
<s n="s2.6;p5.13">The independent variable was the range of numbers from which the targets were chosen. </s>
<s n="s3.6;p5.13">The ranges tested were 1-100, 1-200, 1-400, 1-800 and 1-1600. </s>
<s n="s4.6;p5.13">For each range, 100 trials were performed, and the number of guesses per trial was recorded. </s>
<s n="s5.6;p5.13">The procedure was carried out with both <hi rend="italic">binary search</hi> and <hi rend="italic">random search</hi> algorithms, leading to a total of 1000 trials (2 algorithms x 5 ranges x 100 trials). </s>
<s n="s6.6;p5.13">Two meta-algorithms were implemented to automate data collection. </s>
</p>
</div2>
<div2>
<head rend="bold">Language</head>
<p n="p6.13">
<s n="s1.1;p6.13">The algorithms were implemented in Delphi programming language, and the programme was compiled with a Borland Delphi (v7.0) compiler. </s>
</p>
</div2>
<div2>
<head rend="bold">Algorithm Design</head>
<p n="p7.13">
<s n="s1.4;p7.13">The procedure is the following: the user enters a <hi rend="italic">range</hi> (e.g., 1-100) and think of a number (<hi rend="italic">target number</hi>) within that range; next, the programme <hi rend="italic">guesses</hi> a number and asks if the guess agrees with the target number. </s>
<s n="s2.4;p7.13">If it agrees, the programme halts; otherwise, it calls for feedback. </s>
<s n="s3.4;p7.13">If the target is higher than the guess, then the user enters 'h'; else, she enters 'l'. </s>
<s n="s4.4;p7.13">The algorithms for <hi rend="italic">binary search</hi> and <hi rend="italic">random search</hi> were identical except for the procedure used to guess the target: the first chooses the midpoint of the range, whereas the latter picks a random number. </s>
</p>
</div2>
<div2>
<head rend="bold">Algorithm Complexity</head>
<p n="p8.13">
<s n="s1.6;p8.13">The number of computations necessary to carry out the task is proportional to the size of the search space. </s>
<s n="s2.6;p8.13">The larger the range, the more guesses are needed, in average, to find the target number. </s>
<s n="s3.6;p8.13">Let <hi rend="italic">N</hi> be the length of the search space (e.g. if range = 1-100, then <hi rend="italic">N</hi> = 100). </s>
<s n="s4.6;p8.13">Let <hi rend="italic">ceiling</hi>(x) be the next higher integer above x (e.g., if x = 3.2, then <hi rend="italic">ceiling</hi>(x) = 4). </s>
<s n="s5.6;p8.13">Then, <hi rend="italic">binary search</hi> will take at most <hi rend="italic">ceiling</hi>(log <hi rend="italic"> N</hi>) steps to find the target number, since there are at most <hi rend="italic">ceiling</hi>(<hi rend="italic">log N</hi>) possible ways of splitting the interval 1-<hi rend="italic">N</hi> using the midpoint as the splitting criterion. </s>
<s n="s6.6;p8.13">
<hi rend="italic">Random search</hi>, on the other hand, will take at most <hi rend="italic">N</hi> steps to find the target number: if range = 1-100 and target = 100, it is possible that the sequence of random splittings start from 1 and go stepwisely up to 100, which would require <hi rend="italic">N</hi> = 100 steps. </s>
</p>
</div2>
</div1>
<div1 type="section">
<head rend="bold">Results</head>
<p n="p9.13">
<s n="s1.4;p9.13">The main hypothesis is that <hi rend="italic">binary search</hi> will converge faster to the target than <hi rend="italic">random search</hi>. </s>
<s n="s2.4;p9.13">Specifically, the mean number of guesses in the first case should be sistematically smaller than in the second case. </s>
<s n="s3.4;p9.13">As Table 1 shows, <hi rend="italic">binary search</hi> outperformed <hi rend="italic">random search</hi> in all the ranges tested. </s>
<s n="s4.4;p9.13">In addition, <hi rend="italic">binary search</hi>'s performance varied much less than <hi rend="italic">random search</hi>'s performance, as suggested by the standard deviation scores. </s>
</p>
<table id="BAWE_0088c-tab.001">
<head>
<hi rend="bold">Table 1</hi> . Mean number of guesses produced by binary and random search algorithms</head>
<row>
<cell/>
</row>
</table>
<p n="p10.13">
<s n="s1.4;p10.13">The difference between the two algorithms becomes even more dramatic when one investigates their asymptotic behaviour. </s>
<s n="s2.4;p10.13">The ratio between the mean number of guesses of <hi rend="italic">random search</hi> and <hi rend="italic">binary search</hi> increases as <hi rend="italic">N</hi> tends to infinity. </s>
<s n="s3.4;p10.13">The reason is that, for the former, the number of guesses will linearly increase with the size of the range, whereas for the latter, the number of guesses will increase slowly, following a logarithmic function. </s>
<s n="s4.4;p10.13">Figure 1 illustrates this behaviour: as expected, the two curves diverge as the range size increases (from range 1-800 onwards). </s>
</p>
<figure id="BAWE_0088c-fig.001">
<head>
<hi rend="bold">Figure 1.</hi> Comparison of search algorithms across ranges. As the range increases, random search performance worsens compared to binary search.</head>
</figure>
</div1>
<div1 type="section">
<head rend="bold">Discussion</head>
<p n="p11.13">
<s n="s1.2;p11.13">We have empirically tested two Binary Search algorithms and showed that, as expected by complexity theory, <hi rend="italic">binary search</hi> outperforms <hi rend="italic">random search</hi>. </s>
<s n="s2.2;p11.13">The result illustrates the idea that seemingly minor differences among algorithms can yield large differences in performance, ranging from the worst to the optimal solution. </s>
</p>
<p n="p12.13">
<s n="s1.3;p12.13">The results from <hi rend="italic">random search</hi> were also more variable than <hi rend="italic">binary search</hi>. </s>
<s n="s2.3;p12.13">This was expected, as the split points differ from run to run. </s>
<s n="s3.3;p12.13">While the first guess in <hi rend="italic">binary search</hi> is always 50, in <hi rend="italic">random search</hi>, it can be any number within the range. </s>
</p>
<p n="p13.13">
<s n="s1.6;p13.13">A possible criticism to the experiment is that the targets were not kept constant across algorithms (see Appendix for a sample output). </s>
<s n="s2.6;p13.13">What if the targets for <hi rend="italic">random</hi> <hi rend="italic">search</hi> were harder to guess than for <hi rend="italic">binary search</hi>? </s>
<s n="s3.6;p13.13">Because the 100 targets in each experimental batch were chosen randomly, that possibility seems unlikely. </s>
<s n="s4.6;p13.13">Conversely, if targets were equal across conditions, then a similar point could be raised: that the targets could be easier for either condition. </s>
<s n="s5.6;p13.13">Once again, randomisation would render that possibility unlikely. </s>
<s n="s6.6;p13.13">Therefore, both designs are equivalent.. </s>
</p>
</div1>
</body>
<back>
<div1 type="appendix">
<head rend="bold">Appendix</head>
<p/>
</div1>
</back>
</text>
</TEI.2>

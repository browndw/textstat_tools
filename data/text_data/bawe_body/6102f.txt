Autoregressive exogeneous (ARX) model is mainly used for prediction and control target. This assignment will display how to implement the recursive least squares in the MATLAB to solve the problem. At the beginning, the algorithm is applied to do recursive least squares identification. Subsequently, a mechanical "master" robot of a master/slave tele-manipulator will be identified using some provided real data. At last, the RLS algorithm is extended through introduced the instrument variables.
The ARX is firstly used to identify a model given input and output, and the number of numerator and denominator coefficients. At the beginning of the algorithm, the variable Na, Nb, LN and the true value of A, B are initialized. The function "filter()" is used to calculate the true response of the system, meanwhile the step and random are taken as input to be generated. Theta and P(0) are also initialized, and then perform the recursive least square(RLS) (5),(6),(7),(9) for each output point to estimate the parameters. At last, print out the theta and plot the estimated parameters to compare with the true one. Furthermore, add the noise to the output for comparison with the noiseless one.
In the XiaA.m file, the parameters of model are defined by:
The estimated parameters values are produced through a set of input and output by the file and the figure 1 illustrate that the four parameters promptly converge to their true values. From the figure 1, it is obvious to get that the final estimated parameters value is.
So, the convergence of the estimated parameters towards the true value is pretty well as early as 5 recursion of the algorithm.
In the current section, the random input is introduced into the recursive least algorithm in the same manner just as the step input. Subsequently, the result of comparison between step and random input is easy to inspect.
Due to the same algorithm of the model used, the difference of the convergence evolution is purely caused by the different type of input.
The algorithm is fed 200 random input pairs, and then the estimated parameters are achieved. As the same approach, the true model parameters are defined by.
From the figure 2, the estimated parameters are displayed as.
The figure 2 shows that the estimated parameters are almost exactly same as their true values after probably 5 recursions of the algorithm.
The result of the estimated parameters for the random input is the same as the step one.
Random values are added to the output data to check the effects of noise on the "recursive least squares". The output added the noise is generated thus:
Y=y + random number.
Figure 3 shows the great effect when the noise is added to the prediction of the true system parameters, it is due to the system becomes more complex and unpredictable as the noise is introduced into the system and the algorithm attempts to reach parameters that would produce the same noisy output. The algorithm produces the following estimated parameters.
However, the true parameters is.
It is obvious to discern that the estimated parameters values are not exactly same as the one of the true system.
As it is illustrated in the figure 4, the estimated parameters value has the same condition as the one in figure 3.
So, the estimation varies greatly in accuracy and convergence when dealing with a noisy system, because of the random nature of the noise. It will produce a very different result to another.
In this section, the Recursive least square is now used to identify a real world system from measured input and output data. Data is collected twice with different values for proportional and derivative gain in the system controller. The stability of each of the two set-ups can be indicated by plotting the poles on a Z plane.
Y vector can be produced by the M file "loadass", and take it as the output data of the step input. So they can construct a model to generate the estimated parameters A and B, then the estimated response for the step input is predicted by the "filter" function.
Due to the initials "wx", the two data file in number 25 are loaded into the vector y, and the following pairs are initialized respectively in the algorithm: Na=2 Nb=2; Na=3 Nb=2; Na=3 Nb=3; Na=4 Nb=3. Each of the 4 conditions has 3 associated graphs: pole position, estimated parameter convergence and the estimated response with the actual response.
The model is stable, because all the poles locate inside the unit circle.
The model is stable, because all the poles locate inside the unit circle.
The model is stable, because all the poles locate inside the unit circle.
The model is stable, because all the poles locate inside the unit circle.
All the graphs show that for each setting the models obtained are all stable with all the poles locating inside the unit circle.
All the estimated responses produced by all the models are not exactly same as the actual response of the system, the best model is that of Na=4 Nb=3 where the predicted model step response roughly follows the actual measured response.
The disturbance is considered as no relationship with input in the least square algorithm. However, the disturbance can influence the quality of the model fit greatly. An instrumental variable (IV) can be used in regression analysis to produce a consistent estimator when the explanatory variables are correlated with the error terms. So the IV can be introduced into the RLS to generate recursive instrument least squares algorithm.
In this section, in order to compare the results produced by the algorithm with those obtained in part b, the noise is added and the formula of the algorithm is modified into recursive instrument least squares after initializing the instrument variables Z.
The same data file is loaded into the vector y as part b and just select one setting Na=4 Nb=3 which is the best model to do the comparison.
In the pole position graph, one pole is found that outside the unit circle, which implies that the model will be unstable, unlike those graphs in part B, poles found there are all within the unit circle, the models in part B are relatively stable. It is obvious to discover that the estimated response can follow the actual response at the beginning, but when algorithm iteration goes on, the estimated response oscillates dramatically. So the IV approach is not suitable for all the models, and it depends on the different model.
The ARX model is the simplest model incorporating the stimulus signal. The estimation of the ARX model is the most efficient of the polynomial estimation methods because it is the result of solving linear regression equations in analytic form. Through the experiments and comparison of part b, it is known that the ARX model is preferable, especially when the model order is high. The disadvantage of the ARX model is that the model is easy to be influenced by the noise.

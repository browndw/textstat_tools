In this project, I determined the site percolation threshold of the Kleinberg small-world model (Kleinberg 2000). Site percolation on a lattice consists of labeling each site on the lattice "active" or "inactive." Percolation can be used to model the spread of epidemics and catalytic surfaces. Applying site percolation to small-world networks could be used to better understand the spread of diseases and innovation. The Kleinberg small-world network (2000) is similar to a two-dimensional version of the Watts-Strogatz small-world model. The main difference between the two models, besides the dimensionality, is that the long-range connections in the Kleinberg model are directed. The main feature that Kleinberg wanted to show is that there is an optimal value to the clustering coefficient, r, for greedy search with local information. The clustering coefficient determines the probability that a long-range bond, say from a to b, is chosen,
Percolation on small-world networks can answer questions about the spread of disease through networks that resemble real human contact networks. In this context the "active" nodes are people who are susceptible to the disease; "inactive" nodes are people who are immune to disease. By determining the effect of different long-distance contact distributions and number of long-distance contacts on the percolation threshold, we can start to answer epidemic prevention questions. One possible question is, "is it more important to reduce the total number of long-range contacts or changing the distribution of long range contacts to make the contacts more 'clustered'?"
Another motivation is my initial motivation: modeling the diffusion of information through high-loss small-world networks. One known issue with Milgram's experiment is that a number of the messages were dropped by intermediate people. In terms of percolation these people would be "inactive" nodes. With both stochastic and deterministic message passing schemes, a message that goes through more steps is more likely to be dropped. Therefore, the average path length of a message that makes it to its destination is shorter than the average shortest path if there were no people who dropped messages. I planned to look into the probability of messages reaching a target at the percolation threshold. As it turned out, just finding the percolation threshold as a function of r and the total number of long connections (N) was difficult enough.
The subject of percolation is very old and the percolation threshold has been determined for practically all 2D (Suding 1999) and 3D (Lorenz 2000) lattices. Lattices are said to percolate if there exists a path from one side of the lattice to the other through only active sites. This group of active sites is called a percolation cluster. Networks, on the other hand, require a different definition of percolation. Percolation on networks requires determining the size of the giant component of the network, after the sites have been labeled active or inactive. Network percolation has been performed on random graphs (Callaway 2000), 1D Watts-Strogatz small-world networks (Newman 1999), 2D Watts-Strogatz small-world networks (Newman 2002), and on Heterogeneous networks (Sander 2002). Due to the similarity between the Kleinberg and Watts-Strogatz models, one limit of my analysis should yield similar results to Newman 2002.
My goal is to determine the percolation threshold as function of the two parameters of the Kleinberg model, the power-law distribution coefficient (or "clustering coefficient") r, and the number of long range connections N. The percolation threshold is defined as the percentage of active sites required to always percolate for infinite size systems.
To find the percolation threshold I used simulations written in C++. The details of my simulations are as follows. I create a square lattice of equal height and width. Each site gets N additional directed long range links. If N is not an integer, then some sites get
I measured the profiles of I(p) for several size systems, Figure 1. The most common method of determining the percolation threshold is to measure pc, say where
My main result is shown in Figure 3. This figure shows how pc varies as a function of r and N. There is a lot to digest in the figure so I will discuss some of the interesting behavior. The first limit to note is the limit of N = 0; this corresponds to a normal square lattice with no long-range connections. The percolation threshold for the square lattice is known to be 0.59274621(13). My simulation calculated pc to be 0.5927. This limit shows, at least partial, functionality of my programs.
This limit is shown in Figure 4. This limit corresponds to long bonds of any length being allowed. This result can be compared with the results of Newman 2002. For both results we see the percolation threshold start at that of the square lattice, 0.5 and 0.5927 for bond and site percolation, respectively. For my results, pc monotonically decreases until N=2, after which pc is a constant value, 0.1897. Newman's results don't show this behavior and if I understand their paper correctly, they don't predict any point where pc should become constant. This discrepancy is because, in that paper, he did not measure pc for N>1 and he used the giant component to determine percolation, whereas I used crossing probability.
My approximation of this limit is shown in Figure 5. The slice of the contour plot is at r=15, a good approximation of the infinite behavior. From the plot we can see that there is a linear decrease in pc until N=2 where pc becomes constant. One interesting thing about this limit is that it can be compared against other lattices because it corresponds to adding some connections to next-nearest neighbors. In terms of lattices, a square lattice has a coordination number (z) of 4, i.e. four neighbors. N=1 and N=2 correspond to z=5 and z=6, respectively. I found that pc for z=5 and z=6 are 0.528 and 0.470. These results can be compared against the percolation threshold of normal lattices. My results for z=5 are smaller than known lattices (ranging from 0.550 to 0.579). The common z=6 lattice is the triangular lattice which has a site percolation threshold of 0.5. In all of these cases, the r= limit have a lower percolation threshold than normal lattices. This is an interesting result, without a clear explanation.
A plot of pc versus r for N=1 and N=2 is shown in Figure 6. For large r, pc approaches some asymptotic value as the "long" links become next-nearest neighbor links, as seen in Figure 5. When r decreases, pc also decreases until it reaches a constant value at r
I studied site percolation on the Kleinberg small-world model. Using numerical simulations I determined the percolation threshold for a wide range of values of the system's two parameters: the "clustering coefficient" r and number of long range links N. The percolation threshold values were corrected for finite-size effects. The percolation threshold contour showed several interesting features. First, I found that for large N, N>2, pc does not change anymore. This result is surprising and warrants further study. I plan to simulate similar systems to see if the result is occurs commonly. Another interesting feature is the limit of small r for N=1 and N=2. In these cases, pc takes on values of
There are a number of "special" values of pc, N, and r. Unfortunately, I have so far been unable to come up with any theories or compelling conjectures for why these values should be important.
Apart from theory, there are some "practical" things that can be gleaned from the main contour plot. If this model was an accurate description of real human networks, then my results could help make several policy positions in regard to epidemics. First, if people on average tend to have more than two long-distance friends, then it is always better to try to reduce pc by increasing r. This means convincing people not to contact very long distance friends. If the average number of long-distance friends is less than one, then it's always better to try to reduce the average number of long-distance friends. If on the other-hand, the goal is to spread innovation, then the exact opposite set of recommendations would be best.

In 1973, Allen Newell declared that it was high time that cognitive psychologists begin integrating their findings into "complete processing models" of human performance. His call was heeded by some and various unified theories of cognition (UTCs) have been developed in the intervening years. The ambitions of these models have been high. Consider this recent encapsulation:
Given this ambitious goal, it is somewhat shocking that an attempt to find any incorporation of affect or emotion into UTCs turns up little except a brief noting of their absence (Newell, 1992). Researchers have developed a considerable body of work about the interactions of emotion and cognition, and yet "cold cognition" biases have been enshrined in UTCs. Perhaps it is time to declare that emotion must be included in human information processing models if Newell's original goals are to be achieved.
This paper proposes a line of work attempting to incorporate the effects of emotion on cognition into the executive-process interactive control (EPIC) architecture of Meyer and Kieras (1997). A potential benefit of such an endeavor is more accurate prediction of performance, particularly when modeling real-world behavior in mission-critical situations where there may often be reason for emotion to run high. It is precisely these situations, since they are difficult to simulate in a test environment, where modeling can potentially provide the greatest benefit.
This paper begins by discussing what UTCs are and what they attempt to do. Following this is a sampling of theoretical and empirical work illustrating why emotions are relevant to UTCs. It then discusses a past effort at modeling emotion-cognition interactions in a general way, thus providing a historical precedent for the incorporation of emotion into computational models of cognition. Finally, it describes EPIC and proposes ways in which the effect of emotion might be incorporated into EPIC.
As described by Newell (1992), a UTC specifies an information processing architecture within which human performance on specific tasks can be modeled. The architecture describes the perceptual, motor and cognitive processes that are composed to perform tasks. The models generated from a UTC are computational models. Furthermore, the UTCs that have been developed to date have all used production rule systems. Thus they operate by manipulating discrete symbols that are either representations of external stimuli or are generated internally. In either case, the symbols are temporarily stored in a working memory. The model proceeds by applying production rules that fire if their conditions are matched by the current state of working memory. When a production rule fires, it can perform transformations on the contents of working memory and initiate actions.
In addition to the fundamental elements of perception, cognition, and action, a crucial part of a UTC is the control structure that organizes the components into meaningful directed behavior. This control structure consists of goals that are accomplished through the execution of sequences of production rules that together form strategies. Additionally, there are executive processes that coordinate the prioritization of goals and strategies. This is a key point, because, as will be discussed below, much of the theoretical work on the interaction of cognition and emotion has centered on control processes that guide human behavior.
Given the broad scope of UTCs, they are ambitious projects that have been undertaken by relatively few researchers. Three major UTC projects are SOAR (Newell, 1992), ACT-R (Anderson, 1996), and EPIC (Meyer & Kieras, 1997). Modeling work with SOAR and ACT-R typically focuses more on the problem solving and reasoning domains, while EPIC, with its emphasis on perceptual-motor systems, has been used for more basic tasks.
A typical type of task to be modeled is a reaction-time (RT) task, where the dependent measures are reaction time and accuracy. Often, instead of a single RT task, the subject may be required to perform multiple tasks simultaneously, or in rapid sequence. These dual-task situations are important because they necessarily engage the executive processes that coordinate multiple tasks (Meyer & Kieras, 1997). Ideally, a model will produce the same patterns of both RT and accuracy data as human subjects. Typically, empirical data is collected first and then a model is developed to fit the data. However, a goal for UTCs is a priori prediction of performance on tasks. This will greatly increase the practical applicability of UTCs by making them useful as modeling tools for developing machines or environments where specific human performance is desired. For example, the inside of an aircraft cockpit could be designed and tested using a computational model, without going to the added expense of building a physical prototype and testing it with actual pilots. The behavior required to fly an airplane requires the execution of multiple tasks simultaneously, from monitoring the various dials, to communicating with air traffic control, to adjusting the course of flight. The more accurately performance is modeled; the more useful the UTC will be.
Given the theoretical goal of UTCs to incorporate disparate findings into a single overarching account of human cognition, and the practical goal of providing accurate predictions in the modeling of actual human performance in applied settings, the stage is set for us to ask how useful emotion might be to this endeavor.
On a theoretical level, arguments for the inclusion of emotion in information processing models begin at least with Simon (1967), who "attempts to show how motivational and emotional controls over cognition can be incorporated into an information-processing system" (Simon, 1967, p.30). In Simon's formulation, the human mind is a serial information processor that works to accomplish one goal at a time, within a hierarchy of goals. When a goal cannot be accomplished directly, sub-goals may be created that must be accomplished first. When a goal is completed, it is "popped off" the goal stack and the next goal up is addressed. If a new task comes along, it is added to the end of a queue where it will be dealt with when the current task is completed. However, this highly linear organization is limited in its ability to deal with unpredicted circumstances that require immediate response -- what Simon calls "real-time needs".
In order to deal with real-time needs, Simon suggests that there is an "interrupt system" that is constantly monitoring the environment and internal states for situations that require immediate attention. When such a situation arises, the interrupt system must stop the current processing and start new processing to address the immediate need. Simon lists three types of real-time needs: "uncertain environmental events" such as a loud bang, physiological needs such as hunger or fatigue, and cognitive associations, by which he means stimuli that have an important learned meaning. Simon argues that his interrupt system exhibits the functions of emotion. Thus, in his view, emotion redirects goal-oriented behavior by detecting and addressing unexpected events whose importance should preempt current behavior. In this view, emotion plays a critical role in the executive control of cognitive processes by preemptively switching between goals.
A limitation of Simon's work is that he argues that the human information processing system is primarily serial in nature. While this view was state of the art at the time he wrote his paper, in the intervening years there has been a general shift to more parallel, distributed views of information processing (both for computers and humans). A more recent paper that deals with the integration of emotion and cognitive processing in a parallel-distributed context is that of Oatley and Johnson-Laird (1987). The emphasis is still on control structures, as they state that "emotions have important cognitive functions, we propose that they are part of a management system to co-ordinate each individual's multiple plans and goals" (Oatley & Johnson-Laird, 1987). In their formulation, there are many largely independent processors that perform various functions and these modules work together to accomplish the goals of the system by executing plans. When a "significant juncture of a plan" occurs, the system shifts into a particular "emotional mode" that alters the prioritization of goals thus potentially modifying the current plan of action.
Oatley and Johnson-Laird's theory provides for more flexibility than did Simon's because instead of swapping a single current goal for a different single goal, there is a shift between modes, which can "invoke a limited suite of goals, action possibilities, and skills" (Oatley & Johnson-Laird, 1987). Furthermore, they specifically state that emotion modes are propagated by "emotion signals" that "have no internal symbolic structure of significance" (Oatley & Johnson-Laird, 1987). That is to say, they are raw signals that change the behavior of the processing modules; they are not symbols that can be manipulated by the general cognitive symbol processing system.
The theoretical work of Simon and Oatley & Johnson-Laird points to a critical role of emotions in the executive processes that switch between tasks and manage the goals of the human information processing system. These are fundamental parts of UTCs.
Other theoretical work has focused on the role of emotion in decision-making. For example, Schwarz (2000) outlines a variety of ways in which decision-making can be modified by emotion. One type of interaction is explicit, that is, a person may introspect on their emotional state when presented with an option, and take that state as a measure of the affective value of the option. This measure may then play a role in the computation of the correct decision to make.
Schwarz (2000) also discusses a second interaction that is implicit. In this case, an emotional state leads an individual to adopt a different strategy for the computation of the decision. Specifically, a positive emotional state may lead to the use of a top-down strategy relying more on prior knowledge and less on the information present, while a negative emotional state may lead to a bottom-up strategy that focuses on present information and tends to ignore prior knowledge (Schwarz, 2000). This modulation of strategy could have important implications for UTCs, which attempt to model the specific strategy a subject uses. If emotional state determines which of multiple strategies are engaged for the completion of a task, then the emotional state must be taken into account to make accurate predictions of performance.
The role of emotion in decision-making is also addressed in the work of Damasio (1996). On the surface, Damasio's gambling task appears to be a purely "cognitive" problem-solving task of the sort that SOAR and ACT-R excel at. However, Damasio has a group of patients who perform normally on standard tests of language, working memory, attention and intellect, and yet they fail to perform like normal subjects on the gambling task. Damasio explains this in terms of his somatic marker hypothesis. Normal subjects learn the task by the association of particular actions with particular emotional states. When making later decisions, the stored associations between emotional states and different options are accessed and used to guide behavior. Damasio calls these emotional states somatic markers because he argues they represent body states. Without the use of these somatic markers, decision-making would depend solely on logical reasoning, which he argues would be too computationally expensive and thus slow for many real world situations. The somatic markers allow the rapid reduction of options to a number that it is feasible to consider logically. Given that one of the goals of UTCs is to model learning and performance in reasoning tasks, this work implies that neglecting emotions will miss an important factor in decision-making. In the worse case, an emotionless model may behave like a patient with a ventromedial pre-frontal lesion.
In the preceding work, the impact of emotion, in general, was discussed relative to a particular type of cognitive process, decision making. Another approach is to consider the impact of a particular emotion on cognitive processing in general. For example, the impact of anxiety on a wide variety of cognitive tasks has been studied (Eysenck and Calvo, 1992). Eysenck and Calvo (1992) note that the general pattern found is that higher anxiety leads to worse performance, particularly when stress is applied. However, this effect seems to depend to some extent on the difficulty of the tasks, and even given this, there are still cases of the opposite effect occurring. The processing efficiency theory is an attempt to provide an explanation for this variety of findings by specifying the way in which anxiety interacts with cognitive processes (Eysenck and Calvo, 1992). In particular, the theory claims that the working memory system is affected by anxiety. In terms of the tripartite model of working memory due to Baddeley (1986), the central executive is impacted the most, with secondary effects on the articulatory loop. However, the theory also states that anxiety may lead to "the allocation of additional processing resources (i.e. effort) and to the initiation of processing activities (e.g. strategies) designed to improve performance" (Eysenck and Calvo, 1992). The implications of these complex modulations of the working memory system are hard to understand from the general language used to describe them. However, if this theory was developed in the context of a UTC, then specific predictions could be made across a variety of tasks. Furthermore, if the theory were valid, the UTC would then account for an important emotional modulator of performance.
Recent empirical work has further focused on emotion and cognitive control structures. Gray (2001) looked at the effects of "approach" and "withdrawal" emotional states on verbal and spatial n-back working memory tasks. Given the stimuli used to invoke the emotional states, the approach state is roughly one of amusement or happiness, while the withdrawal state is one of fear. The finding was that, compared to a neutral baseline, fear (withdrawal) improved spatial memory and reduced verbal memory, while happiness (approach) reduced spatial memory and improved verbal memory. This provided support for the idea that "approach and withdrawal emotional states selectively modulate cognitive control functions to coordinate and prioritize among high-level (cognitive) self-regulatory functions" (Gray, 2001). Again, concerns central to the development of UTCs are impacted by emotional states.
The above discussion was intended to make it clear that there is extensive work, both theoretical and empirical, showing the effect of emotion on cognitive processes. To achieve the goal of accurate computational modeling of cognition, emotion must be accounted for. Given this state of affairs, it is natural to look at a past work incorporating emotion into a computational theory of cognition.
Pfeifer (1988) extensively reviews efforts to computationally model emotions. He notes that there are two broad classes of models. First, there are models whose focus is primarily on emotion and on the prediction of which emotions will be generated when. Second, there are models whose focus is on cognitive processes, where emotion "augments" cognition. However, these models generally deal with very specific tasks. Given this situation, the most general model, and the one that appears to be the closest to a unified theory, is Pfeifer's own theory called "A Framework for Evaluation of Events and Linkages into Emotional Responses" (FEELER). While it is unclear how much of FEELER has actually been implemented computationally, on a theoretical level FEELER attempts to encompass emotion from initial generation through eventual disappearance, in a cognitive context. One of the most interesting features is the use of production rules to model the generation of emotions and the generation of new goals as part of the process of emotion. Pfeifer also emphasizes the point that he needed to add a "physiological working memory" subsystem that would not normally exist in a cognitive model. In dealing with the time course of emotions, Pfeifer discusses the use of decay from memory, and active maintenance of emotional states by feedback among systems. FEELER provides valuable insight into the issues that must be addressed when incorporating emotion into a UTC.
In order to understand how emotion might be dealt with within EPIC, it is necessary to have an understanding of the structure of EPIC. As described by Meyer and Kieras (1997), EPIC is a model of the human information processing system that has been implemented as a working computer program (in the programming language Lisp). Currently, EPIC does not deal with language comprehension or learning. It consists of a number of processors that run independently and in parallel. There are three types of processors: perceptual processors that detect and encode stimuli in the environment, motor processors that initiate actions, and the cognitive processor.
Figure 1. Overview of the EPIC architecture (from Meyer & Kieras, 1997).
The perceptual processors detect stimuli in the environment and place symbolic representations of those stimuli in working memory. There are currently three perceptual processors in EPIC: the auditory processor, the visual processor, and the tactile processor. The perceptual processors operate in parallel, so that multiple stimuli can be detected simultaneously. The time it takes for a stimulus to enter working memory depends on the particular qualities of the stimulus and the modality it is in.
The motor processors receive symbolic commands as input and generate simulated movements as output. There are presently three motor processors in EPIC: the ocular motor processor that controls eye movements, the vocal motor processor that controls speech production, and the manual motor processor that controls hand and finger movements.
The core of EPIC is the cognitive processor. Its main components are working memory and the production rule interpreter. In addition, there is a procedural memory that stores the production rules. The cognitive processor performs cyclically. On each cycle, the production rule interpreter matches the production rules in the procedural memory against the current contents of working memory. If all of the conditions for a rule are met, then its actions are performed. The actions may add or remove items from working memory or send movement commands to the motor processors. On each cycle, all of the rules whose conditions are met fire in parallel.
The working memory is a pure storage system that holds many different types of items that can each have their own structure and properties. Thus the working memory can functionally be thought of as a collection of stores: a verbal storage unit, a visual storage unit, a goal store, etc...
Since EPIC is an implemented computer program that makes detailed predictions about accuracy and reaction times, there are necessarily a number of numerical parameters that specify the time course of different functions. Perhaps the most fundamental is the cycle time of the cognitive processor. In addition, there are parameters for the decay times of different sorts of working memory items, the time taken to encode different sorts of external stimuli, and the time taken to execute various motor commands. These parameters encapsulate details of lower level processes that are not modeled in detail in EPIC, since it focuses on the symbolic level of cognition.
Goal-oriented behavior is possible in EPIC because the production rules can be grouped into sets that only fire when a particular goal is in working memory. Through the use of sub-goals and other control symbols, rules can work together to implement simple or complex strategies to complete tasks. Furthermore, there can be sets of rules that act on the goals and control symbols, thereby implementing task switching, dual-tasking and other executive processes.
The proposal made by this paper is the incorporation of emotion into EPIC in order to assist in attaining the goals of a UTC. The above sections have made it clear why such an endeavor would be useful. This section will provide some preliminary speculations on how such incorporation might take place.
An initial issue is to consider the aspects of emotion that will be dealt with. An eventual goal may be to deal with the entire process of emotion starting with elicitation. However, as a first effort, it may be enough to consider the effects of a given emotional state on task performance. For example, in many experiments (such as Gray (2001), discussed above), an emotional state is induced via viewing of some sort of stimuli in an initial stage, and then performance on a task of interest is measured in a test stage. In such a case, if the desire is to model performance of the task, the emotional state can be considered a given. That is, the effects of the emotional state on task performance can be modeled without dealing with the issue of the process by which the emotion was elicited.
One approach, in keeping with the multi-processor architecture of EPIC, and in analogy with the cognitive processor, would be to introduce an "emotional processor." Such a processor could encapsulate various aspects of the emotion, including maintenance of the emotional state, and provide coordination of the emotional effects on the cognitive, perceptual and motor systems. Support for this approach can be found in the physiological work of LeDoux and others, who have identified brain areas largely dedicated to emotional processing (fear and the amygdala, for example).
While the emotional processor approach has some advantages, another approach might be more in line with the process-oriented cognitive appraisal view of emotion. The argument for this would be that emotion is not a separate system to be set in opposition to the cognitive one, but is a collection of causes and effects, a process, that is manifested across mental systems. Taking this approach to the extreme, there would be no emotional processor. There would simply be certain production rules (cognitive appraisals) whose actions would include certain modifications of the perceptual, cognitive and motor systems. In other words, emotion would simply be a process occurring across other mental systems.
The current evidence probably argues for a hybrid approach. An emotional processor could mediate "non-propositional signals" of the sort advocated by Oatley and Johnson-Laird (1987), and maintain physiological state information of the sort hypothesized by Damasio (1996) and Pfeifer (1988). This information would then lead to various modifications, both qualitative and quantitative, that would take place in EPIC's other processors.
Qualitative changes would be most likely in EPIC's cognitive processor. Specifically, emotions would alter both strategies and goals. The strategy shifts could be at both the task specific level and the executive process level. A major emphasis within EPIC is on the variety of executive control strategies available to subjects. Some of these strategies are more "cautious" while others are more "daring" (Meyer & Kieras, 1997). Emotional modulation of these cautious and daring strategies may be a significant factor in the emotional modulation of control hypothesized by Simon (1967) and found by Gray (2001). In dual-tasking situations, the prioritization of goals may also be manipulated by emotional states. EPIC does not have a dedicated goal prioritization mechanism, so emotional executive control processes would enact goal prioritization by manipulating goal states so as to achieve the desired effects.
In addition to qualitative effects, emotional states may also have quantitative effects on various parts of EPIC. Within the working memory system, a prime consideration will be the decay rates for various types of items. In the past these rates have been set at fixed values for different types of information. For example, the decay rate for phonological codes in verbal working memory has been established based on memory span experiments (Kieras et al., 1999). However, to model the impact of emotion on memory performance (Gray, 2001) may require the modulation of decay rates based on current emotional state.
In the perceptual arena, emotional modulation of detection and encoding parameters may be needed. Specifically, the detection and encoding times within EPIC necessarily reflect speed-accuracy tradeoffs in the underlying perceptual processes. Emotional state may modulate these tradeoffs, thus changing the detection and encoding parameters. Similarly the arousal component of emotion may quantitatively shift the cycle time of the cognitive processor, leading to broad changes in performance.
In the long run, emotional elicitation could also be dealt with in EPIC. A specific set of production rules could handle the appraisal of stimuli by constantly evaluating their emotional significance. Since production rules can fire in parallel in EPIC, these emotional processes could be taking place along with typical task processes. As certain appraisals invoked state changes in the emotional processor, there would be modulations in the task-related activities, as discussed above.
There is a developing body of work exhibiting the influence of emotion on mental processes that have traditionally been considered purely cognitive in nature. As such, emotions are clearly relevant to the goals of unified theories of cognition, namely the successful modeling of human performance on cognitive tasks. In the case of EPIC, which attempts to make detailed predictions about the timing and accuracy of human performance, it may be time to consider the influence of emotion on performance.

{
  "hash": "a5ee4f4eeec8c72202648d6d9d655b4b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 1\"\nauthor: \"My Name\"\noutput:\n  html:\n    fig_caption: yes\n    number_sections: true\n---\n\n\n\n\n# Lab 1 (Set 1): Texts, algorithms, and black-boxes {-}\n\nWe're going to start by unpacking the controversy regarding the syuzhet R package. (The readings are short and posted on Canvas, if you haven't looked at them already.) This is a useful exercise, I think, because it gets to some foundational issues in text analysis--you're going to encounter them in your work so they're worth considering from the beginning.\n\n___\n\\begin{center}\nSTOP!\\\\\nCOMPLETE TASKS 1 \\& 2\n\\end{center} \n___\n\n# Load packages and data\n\nLoad the package that we'll use in this short lab.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(syuzhet)\n```\n:::\n\n\nLoad data from file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(\"../data/sentiment_data.rda\")\n```\n:::\n\n\nThe novels that Jockers uses as examples are included as data, which can be accessed as **sentiment_data**. There are 4 novels, and we'll check their names stored in the **doc_id** column.\n\nFor this demonstration, we'll be using *Madame Bovary*.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: A small corpus included in the cmu.textstat package.\n\n|doc_id          |\n|:---------------|\n|madame_bovary   |\n|portrait_artist |\n|ragged_dick     |\n|silas_lapham    |\n\n\n:::\n:::\n\n\n# Prep the data and calculate sentiment\n\nNext, we do some simple cleaning using **str_squish** from the **stringr** package. Then we'll split the the novel into sentences and calculate a sentiment score for each.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\n# str_squish() is a useful function from readr for getting rid of\n# extra spaces, carriage returns, etc.\nmb <- str_squish(sentiment_data$text[1])\n\n# chunk the novel into sentences\nmb_sentences <- get_sentences(mb)\n\n# calculate and return sentiment scores\nmb_sentiment <- get_sentiment(mb_sentences)\n```\n:::\n\n\nLet's check the data:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Sample sentiment scores.\n\n|     |\n|----:|\n| 1.20|\n| 0.25|\n| 0.00|\n| 1.50|\n| 1.05|\n| 1.20|\n\n\n:::\n:::\n\n\n# Transforming the data\n\nThe next step is to transform the data. Originally, Jockers used a Fourier transformation, which he described as follows:\n\n> Aaron introduced me to a mathematical formula from signal processing called the Fourier transformation. The Fourier transformation provides a way of decomposing a time based signal and reconstituting it in the frequency domain. A complex signal (such as the one seen above in the first figure in this post) can be decomposed into series of symmetrical waves of varying frequencies. And one of the magical things about the Fourier equation is that these decomposed component sine waves can be added back together (summed) in order to reproduce the original wave formâ€“this is called a backward or reverse transformation. Fourier provides a way of transforming the sentiment-based plot trajectories into an equivalent data form that is independent of the length of the trajectory from beginning to end. The frequency domain begins to solve the book length problem.\n\nThis introduced some unwanted outcomes, namely that the resulting wave-forms must begin and end at the same point. The updated function uses a Discrete Cosine Transform (DCT), which is commonly used in data compression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmb_dct <- get_dct_transform(mb_sentiment, low_pass_size = 5, x_reverse_len = 100,\n    scale_vals = FALSE, scale_range = TRUE)\n\nmb_dct <- data.frame(dct = mb_dct) %>%\n    rownames_to_column(\"time\") %>%\n    mutate(time = as.numeric(time))\n```\n:::\n\n\nCheck the data:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Sample transformed scores.\n\n| time|       dct|\n|----:|---------:|\n|    1| 1.0000000|\n|    2| 0.9974733|\n|    3| 0.9924392|\n|    4| 0.9849363|\n|    5| 0.9750217|\n|    6| 0.9627711|\n\n\n:::\n:::\n\n\nFinally, the values can be plotted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mb_dct, type = \"l\", xlab = \"Narrative Time\", ylab = \"Emotional Valence\",\n    col = \"red\")\n```\n\n::: {.cell-output-display}\n![Sentiment in \\textit{Madame Bovary} using transformed values.](Lab_01_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n# Transformed vs. non-transformed data\n\nIn order to better compare the before vs. after, let's create a data frame in which we normalize the narrative time values and scale the sentiment scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmb_df <- mb_sentiment %>%\n    data.frame(sentiment = .) %>%\n    rownames_to_column(\"time\") %>%\n    mutate(time = as.numeric(time)) %>%\n    mutate(time = time/length(mb_sentiment) * 100) %>%\n    mutate(sentiment = 2 * (sentiment - min(sentiment))/(max(sentiment) -\n        min(sentiment)) - 1)\n```\n:::\n\n\nNow, those values can be plotted with the values extracted from DCT.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = mb_dct, aes(x = time, y = dct)) + geom_line(colour = \"tomato\") +\n    geom_point(data = mb_df, aes(x = time, y = sentiment), alpha = 0.25,\n        size = 0.25) + xlab(\"Normalized Narrative Time\") + ylab(\"Scaled Sentiment\") +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![Transformed vs. non-transformed sentiment in \\textit{Madame Bovary}](Lab_01_files/figure-html/year_plot-1.png){width=672}\n:::\n:::\n\n\n\\break\n___\n\\begin{center}\nSTOP!\\\\\nCOMPLETE TASK 3\n\\end{center} \n___\n\n\n\n\n",
    "supporting": [
      "Lab_01_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{"title":"Keyness","markdown":{"headingText":"Keyness","containsRefs":false,"markdown":"\n\nFor this lab, we'll be following many of the same procedures that we've done previously:\n\n* attaching metadata to a corpus using `docvars()`\n* tokenizing using `tokens()`\n* handling multiword expressions using `tokens_compound()`\n* creating a document-feature matrix using `dfm()`\n\nFor today's lab we'll begin some hypothesis testing using news functions from our repository:\n\n* `keyness_table()`\n* `keyness_pairs()`\n* `key_keys()`\n\nWe'll also look at quanteda's function:\n\n* `textstat_keyness()`\n\n## What is **keyness**?\n\nKeyness is a generic term for various tests that compare observed vs. expected frequencies.\n\nThe most commonly used (though not the only option) is called log-likelihood in corpus linguistics, but you will see it else where called a **G-test** goodness-of-fit.\n\nThe calculation is based on a 2 x 2 contingency table. It is similar to a chi-square test, but performs better when corpora are unequally sized.\n\nExpected frequencies are based on the relative size of each corpus (in total number of words N~i~) and the total number of observed frequencies:\n\n$$\nE_i = \\sum_i O_i \\times \\frac{N_i}{\\sum_i N_i}\n$$\nAnd log-likelihood is calculated according the formula:\n\n$$\nLL = 2 \\times \\sum_i O_i \\ln \\frac{O_i}{E_i}\n$$\nA good explanation of its implementation in linguistics can be found here: <http://ucrel.lancs.ac.uk/llwizard.html>\n\nIn addition to log-likelihood, the `textstat_keyness()` function in **quanteda** has other optional measures.\n\nSee here: <https://quanteda.io/reference/textstat_keyness.html>\n\n## Prepare a corpus\n\nWe'll begin, just as we did in the distributions lab.\n\n### Load the needed packages\n\n```{r setup}\n#| message: false\n#| error: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(quanteda)\nlibrary(quanteda.textstats)\nlibrary(gt)\n```\n\nLoad the functions:\n\n```{r}\nsource(\"../R/keyness_functions.R\")\nsource(\"../R/helper_functions.R\")\n```\n\nLoad the data:\n\n```{r}\nload(\"../data/sample_corpus.rda\")\nload(\"../data/multiword_expressions.rda\")\n```\n\n\n### Pre-process the data & create a corpus\n\n```{r data_prep}\n#| message: false\n#| error: false\n#| warning: false\n\nsc <- sample_corpus %>%\n  mutate(text = preprocess_text(text)) %>%\n  corpus()\n```\n\n### Extract meta-data from file names\n\nWe'll extract some meta-data by (1) selecting the **doc_id** column, (2) extracting the initial letter string before the underscore, and (3) renaming the vector **text_type**.\n\n```{r extract_metadata}\ndoc_categories <- sample_corpus %>%\n  dplyr::select(doc_id) %>%\n  mutate(doc_id = str_extract(doc_id, \"^[a-z]+\")) %>%\n  rename(text_type = doc_id)\n```\n\n### Assign the meta-data to the corpus\n\nThe accessor function `docvars()` lets us add or modify data in an object. We're going to use it to assign **text_type** as a variable. Note that **doc_categories** could include more than one column and the assignment process would be the same.\n\n```{r assign_metadata}\ndocvars(sc) <- doc_categories\n```\n\nAnd check the result:\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Partial summary of sample corpus.\"\n\nsc |>\n  summary() |>\n  head(10) |>\n  gt()\n```\n\nNote the new column (**text_type** on the right). We could assign any number of categorical variables to our corpus, which could be used for analysis downstream.\n\n### Create a **dfm**\n\n```{r}\nsc_dfm <- sc %>%\n  tokens(what=\"fastestword\", remove_numbers=TRUE) %>%\n  tokens_compound(pattern = phrase(multiword_expressions)) %>%\n  dfm()\n```\n\n## A corpus composition table\n\nIt is conventional to report out the composition of the corpus or corpora you are using for your study. Here will will sum our tokens by text-type and similarly count the number of texts in each grouping.\n\n```{r}\ncorpus_comp <- ntoken(sc_dfm) %>% \n  data.frame(Tokens = .) %>%\n  rownames_to_column(\"Text_Type\") %>%\n  mutate(Text_Type = str_extract(Text_Type, \"^[a-z]+\")) %>%\n  group_by(Text_Type) %>%\n  summarize(Texts = n(),\n    Tokens = sum(Tokens)) %>%\n  mutate(Text_Type = c(\"Academic\", \"Blog\", \"Fiction\", \"Magazine\", \"News\", \"Spoken\", \"Television/Movies\", \"Web\"))\n```\n\nNow, using `grand_summary_rows()`, we can append a row of totals at the bottom of the table.\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Composition of the sample corpus.\"\n\ncorpus_comp |> \n  gt() |>\n  fmt_integer() |>\n  cols_label(\n    Text_Type = md(\"**Text Type**\"),\n    Texts = md(\"**Texts**\"),\n    Tokens = md(\"**Tokens**\")\n  ) |>\n  grand_summary_rows(\n    columns = c(Texts, Tokens),\n    fns = list(\n      Total ~ sum(.)\n    ) ,\n    fmt = ~ fmt_integer(.)\n    )\n```\n\n## Keyness in **quanteda**\n\nNow that we have a **dfm** we perform keyness calculations. First, let's carry out calculations using `textstat_keyness()`.\n\nWhen we use it with textstat_keyness we are indicating that we want the papers with discipline_cat equal to \"acad\" to be our **target corpus**. The everything else (i.e., \"acad\" == FALSE) will be the **reference corpus**.\n\nThe specific method we're using is log-likelihood, which is designated by \"lr\". Thus keyness will show the tokens that are more frequent in papers written for the *academic* text-type vs. those written for other text-types.\n\n```{r}\nacad_kw <- textstat_keyness(sc_dfm, docvars(sc_dfm, \"text_type\") == \"acad\", measure = \"lr\")\n```\n\nNote the second argument: `docvars(sc_dfm, \"text_type\") == \"acad\"`. That slightly awkward syntax simply produces a logical vector. You could store it and pass the vector the function, as well.\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Tokens with the highest keyness values in the academic text-type when compared to the rest of the sample corpus.\"\n\nacad_kw |>\n  head(10) |>\n  gt() |>\n  fmt_number(columns = \"G2\",\n             decimals = 2)\n```\n\n### Creating sub-corpora\n\nIf we want to compare one text-type (as our target corpus) to another (as our reference corpus), we can easily subset the data.\n\n```{r subset_corpus}\nsub_dfm <- dfm_subset(sc_dfm, text_type == \"acad\" | text_type == \"fic\")\n```\n\nWhen we do this, the resulting data will still include **all** the tokens in the sample corpus, including those that do not appear in either the academic or fiction text-type. To deal with this, we will trim the dfm.\n\n```{r trim_dfm}\nsub_dfm <- dfm_trim(sub_dfm, min_termfreq = 1)\n```\n\nWe'll do the same for fiction.\n\n```{r}\nfic_kw <- textstat_keyness(sub_dfm, docvars(sub_dfm, \"text_type\") == \"fic\", measure = \"lr\")\n```\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Tokens with the highest keyness values in the fiction text-type when compared to the academic text-type.\"\n\nfic_kw |>\n  head(10) |>\n  gt() |>\n  fmt_number(columns = \"G2\",\n             decimals = 2)\n```\n\nNote that if we switch our target and reference corpora (academic as target, fiction as reference), the tail of the keyness table contains the negative values of the original (fiction as target, academic and reference), which you may have already gathered given the formula above.\n\n```{r}\nacad_kw <- textstat_keyness(sub_dfm, docvars(sub_dfm, \"text_type\") == \"acad\", measure = \"lr\")\n```\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Tokens with the lowest keyness values int the academic text-type when compared to the fiction text-type.\"\n\nacad_kw |>\n  tail(10) |>\n  gt() |>\n  fmt_number(columns = \"G2\",\n             decimals = 2)\n```\n\n## Effect size\n\nWhile **quanteda** produces one important piece of information (the amount of evidence we have for an effect), it neglects another (the magnitude of the effect). Whenever we report on significance it is **critical** to report **effect size**. Some common effect size measures include:\n\n* %DIFF - see Gabrielatos and Marchi [-@gabrielatos2011keyness]\n    + Costas has also provided an FAQ with more details <http://ucrel.lancs.ac.uk/ll/DIFF_FAQ.pdf>\n* Bayes Factor (BIC) - see Wilson [-@wilson2013embracing]\n    + You can interpret the approximate Bayes Factor as degrees of evidence against the null hypothesis as follows:\n        - 0-2: not worth more than a bare mention\n        - 2-6: positive evidence against H~0~\n        - 6-10: strong evidence against H~0~\n        - 10: very strong evidence against H~0~\n    + For negative scores, the scale is read as \"in favor of\" instead of \"against\".\n* Effect Size for Log Likelihood (ELL) - see Johnston *et al.* [-@johnston2006measures]\n    + ELL varies between 0 and 1 (inclusive). Johnston *et al.* say \"interpretation is straightforward as the proportion of the maximum departure between the observed and expected proportions\".\n* Relative Risk\n* Odds Ratio\n* Log Ratio - see Andrew Hardie's CASS blog for how to interpret this\n    + Note that if either word has zero frequency then a small adjustment is automatically applied (0.5 observed frequency which is then normalized) to avoid division by zero errors.\n\n### Log Ratio (LR)\n\nYou are welcome to use any of these effect size measures. Our repo comes with a function for calculating Hardie's Log Ratio, which is easy and intuitive.\n\n### The `keyness_table()` function\n\nWe'll start by creating 2 dfms--a target and a reference:\n\n```{r create_dfms}\nacad_dfm <- dfm_subset(sc_dfm, text_type == \"acad\") %>% dfm_trim(min_termfreq = 1)\nfic_dfm <- dfm_subset(sc_dfm, text_type == \"fic\") %>% dfm_trim(min_termfreq = 1)\n```\n\nThen we will use the `keyness_table()` function.\n\n```{r k_table}\n#| error: false\n#| message: false\n\nacad_kw <- keyness_table(acad_dfm, fic_dfm)\n```\n\nAnd check the result:\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Tokens with the highest keyness values in the academic text-type when compared to the fiction text-type.\"\n\nacad_kw |>\n  head(10) |>\n  gt() |>\n  fmt_number(columns = c(\"LL\", \"LR\", \"Per_10.5_Tar\", \"Per_10.5_Ref\", \"DP_Tar\", \"DP_Ref\"),\n             decimals = 2) |>\n  fmt_number(columns = \"PV\",\n             decimals = 5)\n```\n\nThe columns are as follows:\n\n1. **LL**: the keyness value or [**log-likelihood**](http://ucrel.lancs.ac.uk/llwizard.html), also know as a G2 or goodness-of-fit test.\n1. **LR**: the effect size, which here is the [**log ratio**](http://cass.lancs.ac.uk/log-ratio-an-informal-introduction/)\n1. **PV**: the *p*-value associated with the log-likelihood\n1. **AF_Tar**: the absolute frequency in the target corpus\n1. **AF_Ref**: the absolute frequency in the reference corpus\n1. **Per_10.x_Tar**: the relative frequency in the target corpus (automatically calibrated to a normalizing factor, where here is per 100,000 tokens)\n1. **Per_10.x_Ref**: the relative frequency in the reference corpus (automatically calibrated to a normalizing factor, where here is per 100,000 tokens)\n1. **DP_Tar**: the [**deviation of proportions**](https://www.researchgate.net/publication/233685362_Dispersions_and_adjusted_frequencies_in_corpora) (a dispersion measure) in the target corpus\n1. **DP_Ref**: the deviation of proportions in the reference corpus\n\n### Keyness pairs\n\nThere is also a function for quickly generating pair-wise keyness comparisions among multiple sub-corpora. To demonstrate, create a third **dfm**, this time containing news articles.\n\n```{r}\nnews_dfm <- dfm_subset(sc_dfm, text_type == \"news\") %>% dfm_trim(min_termfreq = 1)\n```\n\nTo produce a data.frame comparing more than two sup-corpora, use the `keyness_pairs()` function:\n\n```{r key_pairs, message = FALSE, error=FALSE, warning=FALSE}\nkp <- keyness_pairs(news_dfm, acad_dfm, fic_dfm)\n```\n\nCheck the result:\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Pairwise comparisions of news (target) vs. academic (reference), news (target) vs. fiction (reference), and academic (target) vs. fiction (reference).\"\n\nkp |>\n  head(10) |>\n  gt() |>\n  fmt_number(everything(),\n             decimals = 2)\n```\n\n## Key key words\n\nThe concept of [\"**key key words**\"](https://lexically.net/downloads/version5/HTML/index.html?keykeyness_definition.htm) was introduced by Mike Smith for the WordSmith concordancer. The process compares each text in the target corpus to the reference corpus. Log-likelihood is calculated for each comparison. Then a mean is calculated for keyness and effect size. In addition, a range is provided for the number of texts in which keyness reaches significance for a given threshold. (The default is *p* < 0.05.) That range is returned as a percentage.\n\nIn this way, **key key words** accounts for the dispersion of key words by indicating whether a keyness value is driven by a relatively high frequency in a few target texts or many.\n\n```{r key_keys, message = FALSE, error=FALSE, warning=FALSE}\nkk <- key_keys(acad_dfm, fic_dfm)\n```\n\nAgain, we can look at the first few rows of the table:\n\n```{r}\n#| code-fold: true\n#| tbl-cap: \"Key key words when comparing the academic text-type to the fiction text-type.\"\n\nkk |>\n  head(10) |>\n  gt() |>\n  fmt_number(everything(),\n             decimals = 2)\n```\n\n::: callout-important\n## Pause for Lab Set Question\n\nComplete [Task 1 in Lab Set 2](../lab_sets/LabSet_02.qmd#keyness).\n:::\n\n## Works cited\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"keyness.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","editor":"source"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}